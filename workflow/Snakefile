import os
import os.path
import pandas as pd

configfile: "config/config.yaml"

# sample_table = pd.read_table("all_samples2.tsv", index_col = 0)
sample_table = pd.read_table(config['sample_table'], index_col = 1)
sample_dict = sample_table.to_dict('index')

all_samples = list(sample_table.index)
end1_files = list(os.path.basename(sample_dict[sample]["end1"]) for sample in all_samples)
end2_files = list(os.path.basename(sample_dict[sample]["end2"]) for sample in all_samples)
all_files = end1_files + end2_files
all_files = list(value.replace(".fastq.gz","") for value in all_files)


JAVA_MEM_FRACTION=0.85
CONDAENV ='envs'
PAIRED_END= ('R2' in sample_table.columns)
FRACTIONS= ['R1']
if PAIRED_END: FRACTIONS+= ['R2']

# def get_taxonomy_names():

#     if 'idtaxa_dbs' in config and config['idtaxa_dbs'] is not None:
#         return config['idtaxa_dbs'].keys()
#     else:
#         return []

rule all:
  input:
    "data/model/error_rates_R1.qs",
    "data/model/error_rates_R2.qs",
    "data/stats/Nreads_dada2.txt",
    "data/asv/seqtab_nochimeras_qc.qs"

rule all_qc:
    input:
      expand("workflow/report/quality_profiles/{sample}.png",
        sample = all_samples),
      "output/quality_control/multiqc/multiqc_report.html"

rule clean_qc:
  shell:
    "rm -fr output/quality_control"


rule all_taxonomy_kraken:
  input:
    "data/fasta/asv_sequences.fa",
    "data/taxonomy/kraken_minikraken2_labels.qs"
    
rule all_phyloseq:
  input:
    "data/phyloseq/asv_phyloseq.qs",
    "data/phyloseq/asv_phyloseq_norm.qs",
    "data/phyloseq/div/alphadiv.qs"
    # "data/phyloseq/div/betadiv.qs"
    # "data/phyloseq/div/unifrac_dist.qs"

rule clean:
  shell:
    """rm -r data/asv data/filtered data/stats data/model \
        data/fasta data/taxonomy data/phyloseq logs"""

rule clean_phyloseq:
  shell:
    """rm -r data/phyloseq"""

include: "rules/quality_control.smk"
# include: "rules/dada2.smk"
# include: "rules/taxonomy.smk"
# include: "rules/phyloseq.smk"
