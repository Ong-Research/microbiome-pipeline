import os
import os.path
import pandas as pd
import numpy as np

configfile: "config/config.yaml"

# sample_table = pd.read_table("all_samples2.tsv", index_col = 0)
sample_table = pd.read_table(config['sample_table'], index_col = 1)

sample_table = pd.read_table("samples.tsv", index_col = 1)
sample_table = sample_table.assign(
  merges = lambda df: "output/dada2/merge/" + df["batch"] + "/" +
    df.index + "_asv.qs")

sample_dict = sample_table.to_dict('index')

all_samples = list(sample_table.index)
end1_files = list(os.path.basename(sample_dict[sample]["end1"]) for sample in all_samples)
end2_files = list(os.path.basename(sample_dict[sample]["end2"]) for sample in all_samples)
all_files = end1_files + end2_files
all_files = list(value.replace(".fastq.gz","") for value in all_files)

batches = np.unique(sample_table.batch).tolist()

def get_batch_samples(sample_table, batch):
  """
  gets the samples on a single batch based on the sample table
  """
  out = sample_table[sample_table.batch == batch].index
  
  return list(out)

JAVA_MEM_FRACTION=0.85
CONDAENV ='envs'
PAIRED_END= ('R2' in sample_table.columns)
FRACTIONS= ['R1']
if PAIRED_END: FRACTIONS+= ['R2']

# def get_taxonomy_names():

#     if 'idtaxa_dbs' in config and config['idtaxa_dbs'] is not None:
#         return config['idtaxa_dbs'].keys()
#     else:
#         return []

# rule all:
#   input:
#     "data/model/error_rates_R1.qs",
#     "data/model/error_rates_R2.qs",
#     "data/stats/Nreads_dada2.txt",
#     "data/asv/seqtab_nochimeras_qc.qs"

rule sequence_qc:
    input:
      expand("workflow/report/quality_profiles/{sample}.png",
        sample = all_samples),
      "output/quality_control/multiqc/multiqc_report.html"

rule clean_qc:
  shell:
    "rm -fr output/quality_control workflow/report/quality_profiles"

rule dada2:
  input:
    expand("output/dada2/filtered/{sample}_filtered_R1.fastq.gz",
      sample = all_samples),
    expand("output/dada2/filtered/{sample}_filtered_R2.fastq.gz",
      sample = all_samples),
    expand("output/dada2/summary/{sample}_summary_filtered.tsv",
      sample = all_samples),
    expand("output/dada2/model/{batch}_error_rates_{end}.qs",
      batch = batches, end = ["R1", "R2"]),
    expand("workflow/report/model/{batch}_error_rates_{end}.png",
      batch = batches, end = ["R1", "R2"]),
    expand("output/dada2/merge/{batch}/{sample}_asv.qs",
      batch = batches, sample = all_samples, allow_missing = True),
    expand("output/dada2/asv_batch/{batch}_asv.qs", batch = batches),
    expand("output/dada2/asv_batch/{batch}_summary.tsv", batch = batches),
    "workflow/report/dada2qc/asv_matrix_wo_chim.png",
    "workflow/report/dada2qc/nasvs_by_seqlength.png",
    "workflow/report/dada2qc/nasvs_by_seqabundance.png",
    "workflow/report/dada2qc/dada2steps_vs_abundance.png",
    "workflow/report/dada2qc/dada2steps_vs_relabundance.png"

rule clean_dada2:
  shell:
    "rm -fr output/dada2 workflow/report/dada2qc workflow/report/model"

rule taxonomy:
  input:
    "output/taxa/fasta/asv_sequences.fa"

rule clean_taxonomy:
  shell:
    "rm -fr output/taxa"

# rule all_taxonomy_kraken:
#   input:
#     "data/fasta/asv_sequences.fa",
#     "data/taxonomy/kraken_minikraken2_labels.qs"
    
# rule all_phyloseq:
#   input:
#     "data/phyloseq/asv_phyloseq.qs",
#     "data/phyloseq/asv_phyloseq_norm.qs",
#     "data/phyloseq/div/alphadiv.qs"
#     # "data/phyloseq/div/betadiv.qs"
#     # "data/phyloseq/div/unifrac_dist.qs"

# rule clean:
#   shell:
#     """rm -r data/asv data/filtered data/stats data/model \
#         data/fasta data/taxonomy data/phyloseq logs"""

# rule clean_phyloseq:
#   shell:
#     """rm -r data/phyloseq"""

include: "rules/extra_dust.smk"
include: "rules/quality_control.smk"
include: "rules/dada2.smk"
include: "rules/taxonomy.smk"
# include: "rules/qiime_quicktree.smk"
# include: "rules/phyloseq.smk"
