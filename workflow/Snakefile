import os
import os.path
import pandas as pd
import numpy as np

configfile: "config/config.yaml"

# sample_table = pd.read_table("all_samples2.tsv", index_col = 0)
sample_table = pd.read_table(config['samples_file'], index_col = 1)

# sample_table = pd.read_table("samples.tsv", index_col = 1)
sample_table["batch"] = sample_table["batch"].astype("str")
sample_table = sample_table.assign(
  merges = lambda df: "output/dada2/merge/" + df["batch"] + "/" + df.index + "_asv.qs")

sample_dict = sample_table.to_dict('index')

all_samples = list(sample_table.index)
end1_files = list(os.path.basename(sample_dict[sample]["end1"]) for sample in all_samples)
end2_files = list(os.path.basename(sample_dict[sample]["end2"]) for sample in all_samples)
all_files = end1_files + end2_files
all_files = list(value.replace(".fastq.gz","") for value in all_files)

batches = np.unique(sample_table.batch).tolist()

def get_batch_samples(sample_table, batch):
  """
  gets the samples on a single batch based on the sample table
  """
  out = sample_table[sample_table.batch == batch].index
  
  return list(out)

# JAVA_MEM_FRACTION=0.85
# CONDAENV ='envs'
# PAIRED_END= ('R2' in sample_table.columns)
# FRACTIONS= ['R1']
# if PAIRED_END: FRACTIONS+= ['R2']

rule sequence_qc:
    input:
      expand("workflow/report/quality_profiles/{sample}.png",
        sample = all_samples),
      "output/quality_control/multiqc/multiqc_report.html"

rule clean_qc:
  shell:
    "rm -fr output/quality_control workflow/report/quality_profiles"

rule dada2:
  input:
    expand("output/dada2/filtered/{sample}_filtered_R1.fastq.gz",
      sample = all_samples),
    expand("output/dada2/filtered/{sample}_filtered_R2.fastq.gz",
      sample = all_samples),
    expand("output/dada2/summary/{sample}_summary_filtered.tsv",
      sample = all_samples),
    expand("output/dada2/model/{batch}_error_rates_{end}.qs",
      batch = batches, end = ["R1", "R2"]),
    expand("workflow/report/model/{batch}_error_rates_{end}.png",
      batch = batches, end = ["R1", "R2"]),
    sample_table["merges"].tolist(),
    expand("output/dada2/asv_batch/{batch}_asv.qs", batch = batches),
    expand("output/dada2/asv_batch/{batch}_summary.tsv", batch = batches),
    "output/dada2/remove_chim/asv_mat_wo_chim.qs",
    # "output/dada2/after_qc/asv_mat_wo_chim.qs",
    # "workflow/report/dada2qc/asv_matrix_wo_chim.png",
    # "workflow/report/dada2qc/nasvs_by_seqlength.png",
    # "workflow/report/dada2qc/nasvs_by_seqabundance.png",
    # "workflow/report/dada2qc/dada2steps_vs_abundance.png",
    # "workflow/report/dada2qc/dada2steps_vs_relabundance.png"

rule clean_dada2:
  shell:
    "rm -fr output/dada2 workflow/report/dada2qc workflow/report/model"

kraken_dbs = list(config['kraken_dbs'].keys())
blast_dbs = config['blast']['dbs']

rule taxonomy:
  input:
    "output/taxa/fasta/asv_sequences.fa",
    expand("output/taxa/kraken/{ref}/kraken_results.out",
      ref = kraken_dbs),
    expand("output/taxa/blast/{db}/blast_results.tsv",
      db = blast_dbs),
    expand("output/taxa/kraken_match/{ref}/{db}/kraken_rdata.qs",
      ref = kraken_dbs, db = blast_dbs),
    expand("output/taxa/kraken_match/{ref}/{db}/kraken_hits.qs",
      ref = kraken_dbs, db = blast_dbs),
    "output/taxa/kraken_merged/kraken_rdata.qs",
    "output/taxa/kraken_merged/kraken_hits.qs"

rule clean_taxonomy:
  shell:
    "rm -fr output/taxa"

rule phylotree:
  input:
    "output/phylotree/aligned_sequences.qza",
    "output/phylotree/masked_aligned_sequences.qza",
    "output/phylotree/unrooted_tree.qza",
    "output/phylotree/rooted_tree.qza",
    "output/phylotree/newick/tree.nwk"

rule clean_phylotree:
  shell:
    "rm -fr output/phylotree"

rule mia:
  input:
    asv = "output/dada2/after_qc/asv_mat_wo_chim.qs",
    taxa = "output/taxa/kraken_merged/kraken_rdata.qs",
    tree = "output/phylotree/newick/tree.nwk",
    meta = "output/predada2/meta.tsv"
  output:
    mia = "output/mia/mia_object.qs"
  params:
    prefix = config['asv_prefix'],
    config = "config/config.yaml"
  log:
    "logs/prepare_mia_object.log"
  threads: config["threads"]
  shell:
    """Rscript workflow/scripts/mia/prepare_mia_object.R \
      {output.mia} --asv={input.asv} --taxa={input.taxa} \
      --tree={input.tree} --meta={input.meta} \
      --asv_prefix={params.prefix} --log={log} \
      --config={params.config} --cores={threads}"""

rule clean_mia:
  input:
    """rm -fr output/mia/mia_object.qs"""

rule make_dags:
  output:
    mia_dag = "workflow/report/rulegraph/mia.png",
    dada2_dag = "workflow/report/rulegraph/dada2.png",
    taxonomy_dag = "workflow/report/rulegraph/taxa.png",
    phylo_dag = "workflow/report/rulegraph/phylo.png"
  shell:
    """
    snakemake --forceall --rulegraph mia | dot -Tpng > {output.mia_dag}
    snakemake --rulegraph dada2 | dot -Tpng > {output.dada2_dag}
    snakemake --rulegraph taxonomy | dot -Tpng > {output.taxonomy_dag}
    snakemake --rulegraph phylotree | dot -Tpng > {output.phylo_dag}
    """

#include: "rules/extra_dust.smk"
include: "rules/quality_control.smk"
include: "rules/dada2.smk"
include: "rules/taxonomy.smk"
include: "rules/phylo_tree.smk"
